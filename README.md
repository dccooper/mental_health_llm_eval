# Mental Health LLM Evaluation Framework

This is a lightweight, modular red-teaming and evaluation toolkit for assessing large language models (LLMs) used in mental health contexts.

It evaluates LLM responses across:
- Safety
- Empathy
- Clinical Appropriateness
- Professionalism
- Ethical Alignment

Includes:
- Streamlit-based human-in-the-loop UI
- CLI for batch evaluation
- YAML-driven prompt and rubric definitions
